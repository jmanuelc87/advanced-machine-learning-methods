{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301014e9",
   "metadata": {},
   "source": [
    "## TC 5033\n",
    "## Deep Learning\n",
    "## Transformers\n",
    "\n",
    "#### Activity 4: Implementing a Translator\n",
    "\n",
    "- Objective\n",
    "\n",
    "To understand the Transformer Architecture by Implementing a translator.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Follow the provided code. The code already implements a transformer from scratch as explained in one of [week's 9 videos](https://youtu.be/XefFj4rLHgU)\n",
    "\n",
    "    Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells.  You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n",
    "  \n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Traning a translator\n",
    "    - Translating at least 10 sentences.\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06dc8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchtext==0.17.1\n",
    "# %pip install numpy==1.26.4\n",
    "# %pip install pandas==2.2.3\n",
    "# %pip install -q tatoebatools\n",
    "# %pip install -U -q spacy\n",
    "# %pip install mlflow\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c556e7",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f14d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.hub\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tdata\n",
    "import torch.utils.data.dataset as tdataset\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchtext\n",
    "# torchtext.disable_torchtext_deprecation_warning()\n",
    "\n",
    "import torchtext.transforms as T\n",
    "\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from collections import Counter\n",
    "from tatoebatools import tatoeba\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab72121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        # Allow TensorFloat32 on matmul and convolutions\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "        torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "print(f\"Available device: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85603ab",
   "metadata": {},
   "source": [
    "Get the dataset using tatoebatools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0370fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tatoeba.dir = './translations'\n",
    "\n",
    "spa_sentences_df = tatoeba.get('sentences_detailed', ['spa'])\n",
    "eng_sentences_df = tatoeba.get('sentences_detailed', ['eng'])\n",
    "spa_eng_links_df = tatoeba.get('links', language_codes=['spa', 'eng'])\n",
    "\n",
    "user_languages_df = tatoeba.get('user_languages', language_codes='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8212bdc",
   "metadata": {},
   "source": [
    "Pair spanish and english sentences correctly into a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74317d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_links_df = pd.merge(spa_sentences_df, spa_eng_links_df, how='left', left_on='sentence_id', right_on='sentence_id')\n",
    "spa_eng_translations_df = pd.merge(spa_links_df, eng_sentences_df, how='left', left_on='translation_id', right_on='sentence_id')\n",
    "translations_with_skill_df = pd.merge(spa_eng_translations_df, user_languages_df, how='left', left_on='username_y', right_on='username')\n",
    "\n",
    "filter = (translations_with_skill_df.skill_level >= 2.0) & (translations_with_skill_df.username != np.nan)\n",
    "\n",
    "\n",
    "translations_df = translations_with_skill_df.where(filter).dropna()[['sentence_id_x', 'lang_x', 'text_x', 'sentence_id_y', 'lang_y', 'text_y']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd59004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id_x</th>\n",
       "      <th>lang_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>sentence_id_y</th>\n",
       "      <th>lang_y</th>\n",
       "      <th>text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>Todo el mundo debe aprender por s√≠ mismo al fi...</td>\n",
       "      <td>328580.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>Everyone must learn on their own in the end.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2503.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>Eso no va a cambiar nada.</td>\n",
       "      <td>1872366.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>That doesn't change anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>Eso no va a cambiar nada.</td>\n",
       "      <td>6488765.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>That'll change nothing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119877.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>Han utilizado las matem√°ticas para calcular c√≥...</td>\n",
       "      <td>398983.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>Math has been used to calculate how the Univer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119881.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>Los estudiantes reciben una beca de 15.000 eur...</td>\n",
       "      <td>398984.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>The students receive a 15,000 euro scholarship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126566.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>No s√© d√≥nde vive.</td>\n",
       "      <td>473587.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>I don't know where he lives.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>330031.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>El m√©dico me dijo que dejara el tabaco.</td>\n",
       "      <td>1499361.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>My doctor told me to quit smoking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>330031.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>El m√©dico me dijo que dejara el tabaco.</td>\n",
       "      <td>1499363.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>My doctor told me to give up smoking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>330082.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>√âl me minti√≥.</td>\n",
       "      <td>297564.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>He lied to me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>330691.0</td>\n",
       "      <td>spa</td>\n",
       "      <td>Hay algo de verdad en lo que dice.</td>\n",
       "      <td>8864106.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>There's a bit of truth in what he's saying.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id_x lang_x                                             text_x  \\\n",
       "0         2499.0    spa  Todo el mundo debe aprender por s√≠ mismo al fi...   \n",
       "1         2503.0    spa                          Eso no va a cambiar nada.   \n",
       "2         2503.0    spa                          Eso no va a cambiar nada.   \n",
       "3       119877.0    spa  Han utilizado las matem√°ticas para calcular c√≥...   \n",
       "4       119881.0    spa  Los estudiantes reciben una beca de 15.000 eur...   \n",
       "5       126566.0    spa                                  No s√© d√≥nde vive.   \n",
       "6       330031.0    spa            El m√©dico me dijo que dejara el tabaco.   \n",
       "7       330031.0    spa            El m√©dico me dijo que dejara el tabaco.   \n",
       "8       330082.0    spa                                      √âl me minti√≥.   \n",
       "9       330691.0    spa                 Hay algo de verdad en lo que dice.   \n",
       "\n",
       "   sentence_id_y lang_y                                             text_y  \n",
       "0       328580.0    eng       Everyone must learn on their own in the end.  \n",
       "1      1872366.0    eng                      That doesn't change anything.  \n",
       "2      6488765.0    eng                            That'll change nothing.  \n",
       "3       398983.0    eng  Math has been used to calculate how the Univer...  \n",
       "4       398984.0    eng  The students receive a 15,000 euro scholarship...  \n",
       "5       473587.0    eng                       I don't know where he lives.  \n",
       "6      1499361.0    eng                 My doctor told me to quit smoking.  \n",
       "7      1499363.0    eng              My doctor told me to give up smoking.  \n",
       "8       297564.0    eng                                     He lied to me.  \n",
       "9      8864106.0    eng        There's a bit of truth in what he's saying.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca722ee",
   "metadata": {},
   "source": [
    "Creation of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c1fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 20\n",
    "BATCH_SIZE = 96\n",
    "EMBEDDING_DIM = 256\n",
    "NUM_HEADS = 4\n",
    "D_FF = 2048\n",
    "NUM_LAYERS = 6\n",
    "DROPOUT=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fd1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaEngTranslationDataset(tdata.Dataset):\n",
    "    \n",
    "    def __init__(self, translations_df):\n",
    "        self.translations_df = translations_df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.translations_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.translations_df.iloc[index]\n",
    "        return row.text_x, row.text_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0c784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_dataset = SpaEngTranslationDataset(translations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ba79d",
   "metadata": {},
   "source": [
    "Create vocabulary for both languages english and spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389d42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en_fn = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "tokenizer_es_fn = get_tokenizer('spacy', language='es_core_news_sm')\n",
    "\n",
    "specials = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "\n",
    "def build_vocab(dataset):\n",
    "    es, en = Counter(), Counter()\n",
    "    for spa, eng in dataset:\n",
    "        es_words = tokenizer_es_fn(spa)\n",
    "        en_words = tokenizer_en_fn(eng)\n",
    "        es.update(es_words)\n",
    "        en.update(en_words)\n",
    "    \n",
    "    return vocab(es, specials=specials), vocab(en, specials=specials)\n",
    "\n",
    "\n",
    "es_vocab, en_vocab = build_vocab(translations_dataset)\n",
    "\n",
    "es_vocab.set_default_index(es_vocab['<unk>'])\n",
    "en_vocab.set_default_index(en_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb67551",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VOCAB_SIZE = len(es_vocab)\n",
    "TARGET_VOCAB_SIZE = len(en_vocab)\n",
    "\n",
    "SRC_PAD_IDX = es_vocab['<pad>']\n",
    "SRC_SOS_IDX = es_vocab['<sos>']\n",
    "SRC_EOS_IDX = es_vocab['<eos>']\n",
    "\n",
    "TRG_PAD_IDX = en_vocab['<pad>']\n",
    "TRG_SOS_IDX = en_vocab['<sos>']\n",
    "TRG_EOS_IDX = en_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7580e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokenizer_fn):\n",
    "        super(Tokenizer, self).__init__()\n",
    "        self.tokenizer_fn = tokenizer_fn\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return [ self.tokenizer_fn(line) for line in batch ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa2dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_es_transforms = T.Sequential(\n",
    "        Tokenizer(tokenizer_fn=tokenizer_es_fn),\n",
    "        T.Truncate(max_seq_len=MAX_SEQ_LEN),\n",
    "        T.VocabTransform(vocab=es_vocab),\n",
    "        T.ToTensor(padding_value=SRC_PAD_IDX, dtype=torch.long),\n",
    "        T.PadTransform(max_length=MAX_SEQ_LEN, pad_value=SRC_PAD_IDX),\n",
    "    )\n",
    "\n",
    "text_en_transforms = T.Sequential(\n",
    "        Tokenizer(tokenizer_fn=tokenizer_en_fn),\n",
    "        T.Truncate(max_seq_len=MAX_SEQ_LEN),\n",
    "        T.VocabTransform(vocab=en_vocab),\n",
    "        T.ToTensor(padding_value=TRG_PAD_IDX, dtype=torch.long),\n",
    "        T.PadTransform(max_length=MAX_SEQ_LEN, pad_value=TRG_PAD_IDX),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c33742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_fn(batch):\n",
    "    spa, eng = list(zip(*batch))\n",
    "    return text_es_transforms(spa), text_en_transforms(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303facd4",
   "metadata": {},
   "source": [
    "Creation of Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76b70ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, valid_dataset, test_dataset = tdata.random_split(translations_dataset, lengths=[0.85, 0.10, 0.05], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca5e3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = tdata.DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch_fn, shuffle=False)\n",
    "valid_dataloader = tdata.DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch_fn, shuffle=False)\n",
    "test_dataloader = tdata.DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a5796e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 20])\n",
      "torch.Size([96, 20])\n"
     ]
    }
   ],
   "source": [
    "for spa, eng in train_dataloader:\n",
    "    print(spa.shape)\n",
    "    print(eng.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457e534",
   "metadata": {},
   "source": [
    "### Implementation of Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29943402",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "799ce702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7c8dc75a70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformer import PositionalEncoding, HeadAttention, MultiHeadAttention, EncoderLayer, Encoder, DecoderLayer, Decoder, Transformer\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea98429",
   "metadata": {},
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bebff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding table torch.Size([8, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[22, 28, 17, 30, 29, 51, 38, 34],\n",
       "         [17, 58, 41, 38, 16, 13, 30, 23],\n",
       "         [34, 43, 59, 44, 33,  2, 36, 42],\n",
       "         [39, 25, 54, 22, 43, 38, 14, 55]], device='cuda:0'),\n",
       " torch.Size([4, 8, 32]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(32, 8, vocab_size=64, padding_idx=SRC_PAD_IDX).to(device)\n",
    "\n",
    "print(\"encoding table\", pe.encoding_table.shape)\n",
    "\n",
    "tensor = torch.randint(0, 64, (4, 8)).to(device) # (batch_size, length or time_dim)\n",
    "\n",
    "result = pe(tensor)\n",
    "\n",
    "tensor, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "659ff9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = HeadAttention(32, 2, 8, dropout=0.2, mask=False).to(device)\n",
    "\n",
    "result1 = head(result, result, result)\n",
    "\n",
    "result1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b5c23c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = HeadAttention(32, 2, 8, dropout=0.2, mask=True).to(device)\n",
    "\n",
    "result2 = head(result, result, result)\n",
    "\n",
    "result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abfdd744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MultiHeadAttention(32, 2, 8, dropout=0.2, mask=False).to(device)\n",
    "\n",
    "result3 = mha(result, result, result)\n",
    "\n",
    "result3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25940767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MultiHeadAttention(32, 2, 8, dropout=0.2, mask=True).to(device)\n",
    "\n",
    "result4 = mha(result, result, result)\n",
    "\n",
    "result4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0ae59e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = EncoderLayer(32, 2, 8, 128, dropout=0.2).to(device)\n",
    "\n",
    "result5 = enc(result)\n",
    "\n",
    "result5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caef7bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(32, 2, 8, 128, 64, padding_idx=SRC_PAD_IDX, num_layers=2, dropout=0.2).to(device)\n",
    "\n",
    "result6 = encoder(tensor)\n",
    "\n",
    "result6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba17c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = DecoderLayer(32, 2, 8, 128, dropout=0.2).to(device)\n",
    "\n",
    "result7 = dec(result, result6)\n",
    "\n",
    "result7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96f49c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(32, 2, 8, 128, 64, padding_idx=TRG_PAD_IDX, num_layers=2, dropout=0.2).to(device)\n",
    "\n",
    "result8 = decoder(tensor, result6)\n",
    "\n",
    "result8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8d839c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "Transformer                                             [96, 20, 21016]           --\n",
       "‚îú‚îÄEncoder: 1-1                                          [96, 20, 384]             --\n",
       "‚îÇ    ‚îî‚îÄPositionalEncoding: 2-1                          [96, 20, 384]             --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-1                              [96, 20, 384]             13,873,152\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-2                                  [96, 20, 384]             --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderLayer: 3-2                           [96, 20, 384]             6,000,896\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderLayer: 3-3                           [96, 20, 384]             6,000,896\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderLayer: 3-4                           [96, 20, 384]             6,000,896\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderLayer: 3-5                           [96, 20, 384]             6,000,896\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderLayer: 3-6                           [96, 20, 384]             6,000,896\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderLayer: 3-7                           [96, 20, 384]             6,000,896\n",
       "‚îú‚îÄDecoder: 1-2                                          [96, 20, 21016]           --\n",
       "‚îÇ    ‚îî‚îÄPositionalEncoding: 2-3                          [96, 20, 384]             --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-8                              [96, 20, 384]             8,070,144\n",
       "‚îÇ    ‚îî‚îÄModuleList: 2-4                                  --                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderLayer: 3-9                           [96, 20, 384]             10,425,728\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderLayer: 3-10                          [96, 20, 384]             10,425,728\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderLayer: 3-11                          [96, 20, 384]             10,425,728\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderLayer: 3-12                          [96, 20, 384]             10,425,728\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderLayer: 3-13                          [96, 20, 384]             10,425,728\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderLayer: 3-14                          [96, 20, 384]             10,425,728\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-5                                   [96, 20, 384]             768\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-6                                      [96, 20, 21016]           8,091,160\n",
       "=========================================================================================================\n",
       "Total params: 128,594,968\n",
       "Trainable params: 128,594,968\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 12.35\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 3619.92\n",
       "Params size (MB): 514.38\n",
       "Estimated Total Size (MB): 4134.33\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer = Transformer(\n",
    "        d_model=EMBEDDING_DIM,\n",
    "        num_heads=NUM_HEADS,\n",
    "        max_seq_len=MAX_SEQ_LEN,\n",
    "        d_ff=D_FF,\n",
    "        enc_vocab_size=SOURCE_VOCAB_SIZE,\n",
    "        dec_vocab_size=TARGET_VOCAB_SIZE,\n",
    "        src_pad_idx=SRC_PAD_IDX,\n",
    "        trg_pad_idx=TRG_PAD_IDX,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "\n",
    "source, target = next(iter(train_dataloader))\n",
    "\n",
    "summary(model_transformer, input_data=[source, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30d79e",
   "metadata": {},
   "source": [
    "### Definition of train and test step functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ff626c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, dataloader):\n",
    "    total_loss = torch.zeros(len(dataloader))\n",
    "    \n",
    "    model.train()\n",
    "    for i, (spa_batch, eng_batch) in enumerate(tqdm(dataloader)):\n",
    "        spa_batch, eng_batch = spa_batch.to(device), eng_batch.to(device)\n",
    "        \n",
    "        # compute forward pass\n",
    "        logits = model(spa_batch, eng_batch)\n",
    "\n",
    "        # reshase before passing to loss fn\n",
    "        B, L, C = logits.shape\n",
    "        logits = logits.view(B * L, C)\n",
    "        target = eng_batch.view(B * L)\n",
    "\n",
    "        # compute loss, gradients, and update params\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss = F.cross_entropy(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update metrics\n",
    "        total_loss[i] = loss.item()\n",
    "    \n",
    "    # Compute avg\n",
    "    avg_loss = total_loss.mean()\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75ee27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(model, dataloader):\n",
    "    total_loss = torch.zeros(len(dataloader))\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (spa_batch, eng_batch) in enumerate(dataloader):\n",
    "        spa_batch, eng_batch = spa_batch.to(device), eng_batch.to(device)\n",
    "        \n",
    "        # compute forward pass\n",
    "        logits = model(spa_batch, eng_batch)\n",
    "\n",
    "        # reshase before passing to loss fn\n",
    "        B, L, C = logits.shape\n",
    "        logits = logits.view(B * L, C)\n",
    "        target = eng_batch.view(B * L)\n",
    "       \n",
    "        # compute loss\n",
    "        loss = F.cross_entropy(logits, target)\n",
    "        \n",
    "        # update metrics\n",
    "        total_loss[i] = loss.item()\n",
    "\n",
    "    # Compute avg\n",
    "    avg_loss = total_loss.mean()\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6197bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, test_dataloader, epochs=100):\n",
    "    \n",
    "    mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "    mlflow.set_experiment(\"transformer_model\")\n",
    "    mlflow.autolog()\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "\n",
    "        model = Transformer(\n",
    "            d_model=EMBEDDING_DIM,\n",
    "            num_heads=NUM_HEADS,\n",
    "            max_seq_len=MAX_SEQ_LEN,\n",
    "            d_ff=D_FF,\n",
    "            enc_vocab_size=SOURCE_VOCAB_SIZE,\n",
    "            dec_vocab_size=TARGET_VOCAB_SIZE,\n",
    "            src_pad_idx=SRC_PAD_IDX,\n",
    "            trg_pad_idx=TRG_PAD_IDX,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            dropout=DROPOUT\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print(f\"Epoch={i+1}\")\n",
    "            \n",
    "            train_avg_loss = train_step(model, optimizer, train_dataloader)\n",
    "            valid_avg_loss = validate_step(model, test_dataloader)\n",
    "\n",
    "            mlflow.log_metric(\"train_avg_loss\", train_avg_loss, step=i)\n",
    "            mlflow.log_metric(\"valid_avg_loss\", valid_avg_loss, step=i)\n",
    "            \n",
    "            print(f\"Train Loss={train_avg_loss:>7f} \\t Valid Loss={valid_avg_loss:>7f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98847ff7",
   "metadata": {},
   "source": [
    "### Definition of Model Parameters and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1f31cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:31<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.731358 \t Valid Loss=0.198389\n",
      "Epoch=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:34<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.136884 \t Valid Loss=0.072912\n",
      "Epoch=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:34<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.049901 \t Valid Loss=0.034172\n",
      "Epoch=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:35<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.020418 \t Valid Loss=0.020666\n",
      "Epoch=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:35<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.009577 \t Valid Loss=0.015923\n",
      "Epoch=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:34<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.004672 \t Valid Loss=0.013690\n",
      "Epoch=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:34<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.002086 \t Valid Loss=0.012674\n",
      "Epoch=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:34<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.000582 \t Valid Loss=0.012489\n",
      "Epoch=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:34<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.000112 \t Valid Loss=0.012643\n",
      "Epoch=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2043/2043 [04:33<00:00,  7.47it/s]\n",
      "2024/11/12 18:59:35 INFO mlflow.tracking._tracking_service.client: üèÉ View run angry-vole-14 at: http://127.0.0.1:5000/#/experiments/720540007848179926/runs/4c8409b3a62a4920b6357392df28c3e7.\n",
      "2024/11/12 18:59:35 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/720540007848179926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss=0.000466 \t Valid Loss=0.012068\n"
     ]
    }
   ],
   "source": [
    "model = train(train_dataloader, valid_dataloader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3dad15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = int(time.time())\n",
    "\n",
    "path = f\"./transformer_{timestamp}.pkl\"\n",
    "\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8854a8",
   "metadata": {},
   "source": [
    "### Evaluate sentences using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "500e2e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer2 = Transformer(\n",
    "        d_model=EMBEDDING_DIM,\n",
    "        num_heads=NUM_HEADS,\n",
    "        max_seq_len=MAX_SEQ_LEN,\n",
    "        d_ff=D_FF,\n",
    "        enc_vocab_size=SOURCE_VOCAB_SIZE,\n",
    "        dec_vocab_size=TARGET_VOCAB_SIZE,\n",
    "        src_pad_idx=SRC_PAD_IDX,\n",
    "        trg_pad_idx=TRG_PAD_IDX,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model_transformer2.load_state_dict(torch.load('transformer_1731437975.pkl', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4ac6f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¬°Que se borre su nombre!',\n",
       " 'Me estaba helando.',\n",
       " 'Aprend√≠ ingl√©s por internet.',\n",
       " 'Necesito saber m√°s detalles.',\n",
       " 'Cuanto antes vayas, mejor.',\n",
       " '\"¬øPor qu√© est√° Tom enfermo?\" \"Podr√≠a haber comido algo en mal estado\".',\n",
       " 'La artista cedi√≥ su obra al dominio p√∫blico.',\n",
       " 'Los pueblos de las Primeras Naciones tienen historias interesantes que contar.',\n",
       " '¬øMe ves?',\n",
       " 'Gracias por mostrarme c√≥mo se hace.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = translations_df['text_x'].sample(10).to_list()\n",
    "\n",
    "test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "09809ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_sentence(indices, en_vocab):\n",
    "    return ' '.join(en_vocab.lookup_token(idx) for idx in indices if en_vocab.lookup_token(idx) != '<pad>' and en_vocab.lookup_token(idx) != '<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c26c2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, en_vocab, max_seq_len=MAX_SEQ_LEN):\n",
    "    src = text_es_transforms([sentence])\n",
    "    tgt = torch.zeros((1,1), dtype=torch.long).to(device)\n",
    "\n",
    "    for _ in range(max_seq_len):\n",
    "        # crop the last max seq len indices\n",
    "        tgt_cond = tgt[:, -max_seq_len:]\n",
    "        # evaluate the model\n",
    "        logits = model(src.to(device), tgt_cond.to(device))\n",
    "        # focus only on the last time step\n",
    "        logits = logits[:, -1, :]\n",
    "        # apply softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        idx_next = torch.multinomial(probs, num_samples=1, replacement=False)\n",
    "        \n",
    "        if idx_next.cpu().item() == en_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "        tgt = torch.cat((tgt, idx_next), dim=1)\n",
    "    return tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "708cee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentences(model, sentences, en_vocab, max_seq_len=MAX_SEQ_LEN):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence in sentences:\n",
    "            sequence = translate_sentence(model, sentence, en_vocab, max_seq_len)\n",
    "            translation = indices_to_sentence(sequence[0], en_vocab)\n",
    "            yield sentence, translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c26640ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Que se borre su nombre! \n",
      " duff duff duff duff duff duff duff duff duff duff duff duff duff duff duff duff duff duff duff duff\n",
      "Me estaba helando. \n",
      " Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays Holidays\n",
      "Aprend√≠ ingl√©s por internet. \n",
      " koala koala koala koala koala koala koala koala koala koala koala koala koala koala koala koala koala koala koala koala\n",
      "Necesito saber m√°s detalles. \n",
      " crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned crowned\n",
      "Cuanto antes vayas, mejor. \n",
      " trim trim trim trim trim trim trim trim trim trim trim trim trim trim trim trim trim trim trim trim\n",
      "\"¬øPor qu√© est√° Tom enfermo?\" \"Podr√≠a haber comido algo en mal estado\". \n",
      " principles principles principles principles principles principles principles principles principles principles principles principles principles principles principles principles principles principles principles principles\n",
      "La artista cedi√≥ su obra al dominio p√∫blico. \n",
      " Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary Veterinary\n",
      "Los pueblos de las Primeras Naciones tienen historias interesantes que contar. \n",
      " nest nest nest nest nest nest nest nest nest nest nest nest nest nest nest nest nest nest nest nest\n",
      "¬øMe ves? \n",
      " Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless Needless\n",
      "Gracias por mostrarme c√≥mo se hace. \n",
      " culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally culturally\n"
     ]
    }
   ],
   "source": [
    "for sentence, translation in evaluate_sentences(model_transformer2, test_sentences, en_vocab):\n",
    "    print(f\"{sentence} \\n {translation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
